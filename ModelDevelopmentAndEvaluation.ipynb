{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1A4iTotIDT4Tj6WC0_lhp050N5n5vRbzw","authorship_tag":"ABX9TyNHppqy+5jfUKB5gCo/mFTo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# CS284A Final Project - Model and Evaluation Code\n","# Kai Silkwood, Thao Nguyen\n","\n","---\n","\n","\n","## Data Import and Formatting"],"metadata":{"id":"TkVVb4NR-BOA"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"hJfKfJGJXkjX","executionInfo":{"status":"ok","timestamp":1702054491955,"user_tz":480,"elapsed":9243,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import joblib\n","from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/',force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vb1Wt6cXcqln","executionInfo":{"status":"ok","timestamp":1702054503210,"user_tz":480,"elapsed":11258,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"70e7a71e-8de6-4437-84a0-a27b2a6aa471"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["from torch._C import dtype\n","from torch.utils.data import Dataset\n","\n","class barcode_dataset(Dataset):\n","  def __init__(self, X, Y):\n","    super(barcode_dataset, self).__init__()\n","    self.X = X\n","    self.Y = Y\n","\n","  def __len__(self):\n","    return self.X.shape[0]\n","\n","  def __getitem__(self, idx):\n","    return self.X[idx], self.Y[idx]"],"metadata":{"id":"h-ked6QlX4ro","executionInfo":{"status":"ok","timestamp":1702054503211,"user_tz":480,"elapsed":7,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Import training data\n","zBC1 = np.loadtxt(\"/content/drive/MyDrive/CS284AProject/train_Pad_0s_BC1.txt\")\n","BC1z = np.loadtxt(\"/content/drive/MyDrive/CS284AProject/train_Pad_BC1_0s.txt\")\n","zBC2 = np.loadtxt(\"/content/drive/MyDrive/CS284AProject/train_Pad_0s_BC2.txt\")\n","BC2z = np.loadtxt(\"/content/drive/MyDrive/CS284AProject/train_Pad_BC2_0s.txt\")\n","\n","zBC1y = torch.load(\"/content/drive/MyDrive/CS284AProject/train_tensor_y_0s_BC1.pt\")\n","BC1zy = torch.load(\"/content/drive/MyDrive/CS284AProject/train_tensor_y_BC1_0.pt\")\n","zBC2y = torch.load(\"/content/drive/MyDrive/CS284AProject/train_tensor_y_0s_BC2.pt\")\n","BC2zy = torch.load(\"/content/drive/MyDrive/CS284AProject/train_tensor_y_BC2_0s.pt\")\n","\n","#Import testing data\n","BC1BC1 = np.loadtxt(\"/content/drive/MyDrive/CS284AProject/signalBC11.txt\")\n","BC1BC2 = np.loadtxt(\"/content/drive/MyDrive/CS284AProject/signalBC12.txt\")\n","BC2BC2= np.loadtxt(\"/content/drive/MyDrive/CS284AProject/signalBC22.txt\")\n","BC2BC1 = np.loadtxt(\"/content/drive/MyDrive/CS284AProject/signalBC21.txt\")"],"metadata":{"id":"V7t8TupiZpiW","executionInfo":{"status":"ok","timestamp":1702054506312,"user_tz":480,"elapsed":3106,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["BC1BC1.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTUHCpIn7FeD","executionInfo":{"status":"ok","timestamp":1702054506313,"user_tz":480,"elapsed":7,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"88112cbf-2c75-4359-967d-3002ae17eb51"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 184)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#Create labels for testing data\n","ones = np.ones(92)\n","zeros = np.zeros(92)\n","\n","zeros_zeros = np.concatenate((zeros, zeros))\n","ones_zeros = np.concatenate((ones, zeros))\n","zeros_ones = np.concatenate((zeros, ones))\n","ones_ones = np.concatenate((ones, ones))\n","\n","zeros_zeros2D = np.tile(zeros_zeros, (100,1))\n","ones_zeros2D = np.tile(ones_zeros, (100,1))\n","zeros_ones2D = np.tile(zeros_ones, (100,1))\n","ones_ones2D = np.tile(ones_ones, (100,1))\n","\n","np.array((zeros_zeros2D, ones_ones2D, zeros_zeros2D))\n","\n","BC1BC1y = torch.tensor(np.tile(np.array((zeros_zeros, ones_ones, zeros_zeros)), (100,1))).reshape([100,3,184])\n","BC1BC2y = torch.tensor(np.tile(np.array((zeros_zeros, ones_zeros, zeros_ones)),(100,1))).reshape([100,3,184])\n","BC2BC1y = torch.tensor(np.tile(np.array((zeros_zeros, zeros_ones, ones_zeros)),(100,1))).reshape([100,3,184])\n","BC2BC2y = torch.tensor(np.tile(np.array((zeros_zeros, zeros_zeros, ones_ones)),(100,1))).reshape([100,3,184])"],"metadata":{"id":"MaM4Q0qI2UEi","executionInfo":{"status":"ok","timestamp":1702054529892,"user_tz":480,"elapsed":187,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#Check that shapes are what we expect\n","BC1BC1y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D0I7vDQ65Xyc","executionInfo":{"status":"ok","timestamp":1702054529892,"user_tz":480,"elapsed":2,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"3c3a150f-3d08-4d0a-e2d0-66727536f08a"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 3, 184])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["zBC1y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AokOwCFi56LH","executionInfo":{"status":"ok","timestamp":1702054530040,"user_tz":480,"elapsed":2,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"51d9a9b0-e2bf-40cc-a4a6-8cbb65913c04"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 3, 184])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["train_X = torch.from_numpy(np.concatenate((zBC1, BC1z, zBC2, BC2z)))\n","train_Y = torch.cat((zBC1y, BC1zy, zBC2y, BC2zy))\n","\n","test_X = torch.from_numpy(np.concatenate((BC1BC1, BC1BC2, BC2BC1, BC2BC2)))\n","test_Y = torch.cat((BC1BC1y, BC1BC2y, BC2BC1y, BC2BC2y))"],"metadata":{"id":"2GuqAUHkdJ9Q","executionInfo":{"status":"ok","timestamp":1702054530454,"user_tz":480,"elapsed":2,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["train_data = barcode_dataset(train_X, train_Y)\n","test_data = barcode_dataset(test_X, test_Y)"],"metadata":{"id":"x9t6QgyKdzWY","executionInfo":{"status":"ok","timestamp":1702054530623,"user_tz":480,"elapsed":3,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["batch_size = 100\n","train_data_tc = torch.utils.data.DataLoader(dataset=train_data, batch_size = batch_size, shuffle=True)\n","test_data_tc = torch.utils.data.DataLoader(dataset=test_data, batch_size = batch_size, shuffle=True)"],"metadata":{"id":"1ZLkz0myer-m","executionInfo":{"status":"ok","timestamp":1702054530623,"user_tz":480,"elapsed":2,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["X,Y= next(iter(train_data_tc))"],"metadata":{"id":"ms9eY57Ge5Eu","executionInfo":{"status":"ok","timestamp":1702054530781,"user_tz":480,"elapsed":2,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVnE8qPXfwEe","executionInfo":{"status":"ok","timestamp":1702054531087,"user_tz":480,"elapsed":5,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"537dd65f-9d1c-41dd-9f56-290a73a60536"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 184])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["Y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7_JIQHPfxf-","executionInfo":{"status":"ok","timestamp":1702054531087,"user_tz":480,"elapsed":4,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"5109935d-f82f-45ec-d2d8-d4599b12a1b5"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 3, 184])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["class LSTM_Classifier(nn.Module):\n","  def __init__(self, input_size = 1, hidden_size = 128, hidden_size2 = 64, dropout_rate = 0.2, num_layers = 2):\n","    super(LSTM_Classifier, self).__init__()\n","\n","    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n","\n","    self.layer1 = nn.Sequential(\n","        nn.Linear(hidden_size, hidden_size2),\n","        nn.ReLU(),\n","        nn.Dropout(dropout_rate),\n","    )\n","\n","    self.fc = nn.Linear(hidden_size2, 3)\n","    self.fc2 = nn.Linear(hidden_size, 3)\n","    self.activation = nn.Softmax(dim=2)\n","\n","  def forward(self, X):\n","    batch_size, seq_length = X.size()\n","    out = X.unsqueeze(-1).to(torch.float32)\n","    lstm_out, _ = self.lstm(out)\n","    out = lstm_out.view(batch_size, seq_length, -1)\n","\n","    #out = self.layer1(out)\n","    #out = self.fc(out)\n","\n","    out = self.fc2(out)\n","    #out = self.activation(out)\n","\n","    return out.reshape([batch_size, -1, seq_length])"],"metadata":{"id":"7OXLWAYpf-Xl","executionInfo":{"status":"ok","timestamp":1702054531467,"user_tz":480,"elapsed":2,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## LSTM"],"metadata":{"id":"6ZErvXDk8G6D"}},{"cell_type":"code","source":["lstm_model2 = LSTM_Classifier()\n","num_epochs = 250\n","learning_rate = 0.0001\n","optimizer = torch.optim.Adam(lstm_model2.parameters(), lr=learning_rate)\n","\n","weights = torch.tensor([1., 10., 10.])\n","criterion = nn.CrossEntropyLoss(weight=weights)\n","\n","total_step = len(train_data_tc)\n","for epoch in range(num_epochs):\n","  for i, (X, Y) in enumerate(train_data_tc):\n","\n","    #Forward pass\n","    output = lstm_model2(X)\n","    loss = criterion(output, Y.to(torch.float32))\n","    #Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  if (epoch+1) % 10==0:\n","    print(f\"Epoch: {epoch+1}/{num_epochs} - Loss: {loss.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oqnBvy-m8QSg","executionInfo":{"status":"ok","timestamp":1702068189206,"user_tz":480,"elapsed":1675115,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"55fe2ce9-9ec6-434a-e026-d968a0cc4ecc"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 10/250 - Loss: 5.405324935913086\n","Epoch: 20/250 - Loss: 5.304596424102783\n","Epoch: 30/250 - Loss: 4.866156578063965\n","Epoch: 40/250 - Loss: 4.296767234802246\n","Epoch: 50/250 - Loss: 4.16372537612915\n","Epoch: 60/250 - Loss: 4.205380439758301\n","Epoch: 70/250 - Loss: 4.04855489730835\n","Epoch: 80/250 - Loss: 3.5079832077026367\n","Epoch: 90/250 - Loss: 3.649627685546875\n","Epoch: 100/250 - Loss: 3.22391939163208\n","Epoch: 110/250 - Loss: 3.1400790214538574\n","Epoch: 120/250 - Loss: 2.5436880588531494\n","Epoch: 130/250 - Loss: 2.3026633262634277\n","Epoch: 140/250 - Loss: 2.466386318206787\n","Epoch: 150/250 - Loss: 2.130204439163208\n","Epoch: 160/250 - Loss: 1.9149889945983887\n","Epoch: 170/250 - Loss: 2.1536734104156494\n","Epoch: 180/250 - Loss: 2.2821309566497803\n","Epoch: 190/250 - Loss: 2.3024563789367676\n","Epoch: 200/250 - Loss: 0.7363616824150085\n","Epoch: 210/250 - Loss: 0.585777997970581\n","Epoch: 220/250 - Loss: 0.469929039478302\n","Epoch: 230/250 - Loss: 0.44687265157699585\n","Epoch: 240/250 - Loss: 0.38582244515419006\n","Epoch: 250/250 - Loss: 0.34946316480636597\n"]}]},{"cell_type":"code","source":["import itertools\n","y_pred_list = []\n","y_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(test_data_tc):\n","    output = lstm_model2(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        y_pred_list.append(np.argmax(classed))\n","        y_target_list.append(np.argmax(this_target))\n","\n","y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n","y_target_list = [a.squeeze().tolist() for a in y_target_list]\n","\n","#Training accuracy\n","x_pred_list = []\n","x_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(train_data_tc):\n","    output = lstm_model2(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        x_pred_list.append(np.argmax(classed))\n","        x_target_list.append(np.argmax(this_target))\n","\n","x_pred_list = [a.squeeze().tolist() for a in x_pred_list]\n","\n","x_target_list = [a.squeeze().tolist() for a in x_target_list]\n","\n","conf_matrix = confusion_matrix(y_target_list, y_pred_list)\n","print(\"Confusion Matrix of the Test Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(y_pred_list, y_target_list)))\n","print(\"_______________________\")\n","conf_matrix = confusion_matrix(x_target_list, x_pred_list)\n","print(\"Confusion Matrix of the Training Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(x_pred_list, x_target_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rk9l5Xf8sxF","executionInfo":{"status":"ok","timestamp":1702068199331,"user_tz":480,"elapsed":10130,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"f6c2507a-381f-44e0-dc06-4b88917d9055"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix of the Test Set\n","-----------------------\n","[[    0     0     0]\n"," [ 7476  8390 20934]\n"," [12258  3627 20915]]\n","Precision:\t0.39816576086956523\n","Recall:\t0.39816576086956523\n","F1 Score:\t0.39816576086956523\n","Accuracy:\t0.39816576086956523\n","_______________________\n","Confusion Matrix of the Training Set\n","-----------------------\n","[[30550  2598  6852]\n"," [    0 16800     0]\n"," [    0     7 16793]]\n","Precision:\t0.8715081521739131\n","Recall:\t0.8715081521739131\n","F1 Score:\t0.8715081521739131\n","Accuracy:\t0.8715081521739131\n"]}]},{"cell_type":"code","source":["#Accuracy of just the barcode classes\n","(8390+20915)/(7476+12258+8390+20934+12258+3627+20915)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bgeklKyMPQX5","executionInfo":{"status":"ok","timestamp":1702069389880,"user_tz":480,"elapsed":124,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"45c0c705-d011-43a0-cbbb-73e012a4261e"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.341319387826411"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["#Accuracy per length of one barcode rather than per time point\n","import itertools\n","y_pred_list = []\n","y_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(test_data_tc):\n","    output = lstm_model2(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      row_preds = []\n","      row_targets = []\n","\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        row_preds.append(np.argmax(classed))\n","        row_targets.append(np.argmax(this_target))\n","\n","        if (col+1)%92==0:\n","           row_mode_pred = max(set(row_preds), key = row_preds.count)\n","           row_mode_target = max(set(row_targets), key = row_targets.count)\n","\n","           y_pred_list.append(row_mode_pred)\n","           y_target_list.append(row_mode_target)\n","\n","           row_preds = []\n","           row_targets =[]\n","\n","y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n","y_target_list = [a.squeeze().tolist() for a in y_target_list]\n","\n","\n","#Training accuracy\n","x_pred_list = []\n","x_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(train_data_tc):\n","    output = lstm_model2(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      row_preds = []\n","      row_targets = []\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        row_preds.append(np.argmax(classed))\n","        row_targets.append(np.argmax(this_target))\n","\n","        if (col+1)%92==0:\n","           row_mode_pred = max(set(row_preds), key = row_preds.count)\n","           row_mode_target = max(set(row_targets), key = row_targets.count)\n","\n","           x_pred_list.append(row_mode_pred)\n","           x_target_list.append(row_mode_target)\n","\n","           row_preds = []\n","           row_targets = []\n","\n","x_pred_list = [a.squeeze().tolist() for a in x_pred_list]\n","\n","x_target_list = [a.squeeze().tolist() for a in x_target_list]\n","\n","conf_matrix = confusion_matrix(y_target_list, y_pred_list)\n","print(\"Confusion Matrix of the Test Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(y_pred_list, y_target_list)))\n","print(\"________________________\")\n","conf_matrix = confusion_matrix(x_target_list, x_pred_list)\n","print(\"Confusion Matrix of the Training Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(x_pred_list, x_target_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0ka6hvHQK7U","executionInfo":{"status":"ok","timestamp":1702069631755,"user_tz":480,"elapsed":17891,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"3657f25e-4567-41cf-f505-96ac529e7aa6"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix of the Test Set\n","-----------------------\n","[[  0   0   0]\n"," [ 73  64 263]\n"," [ 54  93 253]]\n","Precision:\t0.39625\n","Recall:\t0.39625\n","F1 Score:\t0.39625\n","Accuracy:\t0.39625\n","________________________\n","Confusion Matrix of the Training Set\n","-----------------------\n","[[400   0   0]\n"," [  0 200   0]\n"," [  0   0 200]]\n","Precision:\t1.0\n","Recall:\t1.0\n","F1 Score:\t1.0\n","Accuracy:\t1.0\n"]}]},{"cell_type":"code","source":["#Per Barcode Accuracy\n","(64+253)/(73+64+263+54+93+253)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HsFW8_liR62J","executionInfo":{"status":"ok","timestamp":1702070072569,"user_tz":480,"elapsed":129,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"33d883c1-2cd3-4e6e-ca4b-90b8e0950ee9"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.39625"]},"metadata":{},"execution_count":82}]},{"cell_type":"markdown","source":["## LSTM-0Weight\n"],"metadata":{"id":"AApAwI1i8DhR"}},{"cell_type":"code","source":["lstm_model = LSTM_Classifier()\n","output = lstm_model(X)"],"metadata":{"id":"0O3VW2vSp4hM","executionInfo":{"status":"ok","timestamp":1702062034873,"user_tz":480,"elapsed":157,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KbnZm5aUUyEQ","executionInfo":{"status":"ok","timestamp":1702062035039,"user_tz":480,"elapsed":169,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"0cd2179c-f7b0-403c-dd3c-470d9b063027"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 3, 184])"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["num_epochs = 150\n","learning_rate = 0.0001\n","optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate)\n","\n","weights = torch.tensor([0., 1., 1.])\n","criterion = nn.CrossEntropyLoss(weight=weights)"],"metadata":{"id":"OXkcPBpQUduh","executionInfo":{"status":"ok","timestamp":1702062035039,"user_tz":480,"elapsed":3,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["criterion(lstm_model(X),Y.to(torch.float32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3TKyQZRcEe-","executionInfo":{"status":"ok","timestamp":1702062035455,"user_tz":480,"elapsed":419,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"706b8494-5226-480e-8cdf-0f05f6f15671"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.5024, grad_fn=<DivBackward1>)"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["total_step = len(train_data_tc)\n","for epoch in range(num_epochs):\n","  for i, (X, Y) in enumerate(train_data_tc):\n","\n","    #Forward pass\n","    output = lstm_model(X)\n","    loss = criterion(output, Y.to(torch.float32))\n","    #Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  if (epoch+1) % 10==0:\n","    print(f\"Epoch: {epoch+1}/{num_epochs} - Loss: {loss.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5VNJXIyIVizI","executionInfo":{"status":"ok","timestamp":1702063228570,"user_tz":480,"elapsed":1193118,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"59ce44a9-ac0f-41c5-fc63-d314e123c738"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 10/150 - Loss: 0.4891889691352844\n","Epoch: 20/150 - Loss: 0.473030686378479\n","Epoch: 30/150 - Loss: 0.38718703389167786\n","Epoch: 40/150 - Loss: 0.34407684206962585\n","Epoch: 50/150 - Loss: 0.32686954736709595\n","Epoch: 60/150 - Loss: 0.3209340274333954\n","Epoch: 70/150 - Loss: 0.32205379009246826\n","Epoch: 80/150 - Loss: 0.3204686939716339\n","Epoch: 90/150 - Loss: 0.31925535202026367\n","Epoch: 100/150 - Loss: 0.3188161253929138\n","Epoch: 110/150 - Loss: 0.31909269094467163\n","Epoch: 120/150 - Loss: 0.31839221715927124\n","Epoch: 130/150 - Loss: 0.31792718172073364\n","Epoch: 140/150 - Loss: 0.31763744354248047\n","Epoch: 150/150 - Loss: 0.31800612807273865\n"]}]},{"cell_type":"code","source":["import itertools\n","y_pred_list = []\n","y_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(test_data_tc):\n","    output = lstm_model(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        y_pred_list.append(np.argmax(classed))\n","        y_target_list.append(np.argmax(this_target))\n","\n","y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n","y_target_list = [a.squeeze().tolist() for a in y_target_list]\n"],"metadata":{"id":"5Nl751t8Ou58","executionInfo":{"status":"ok","timestamp":1702063234504,"user_tz":480,"elapsed":5937,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["#Training accuracy\n","x_pred_list = []\n","x_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(train_data_tc):\n","    output = lstm_model(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        x_pred_list.append(np.argmax(classed))\n","        x_target_list.append(np.argmax(this_target))\n","\n","x_pred_list = [a.squeeze().tolist() for a in x_pred_list]\n","\n","x_target_list = [a.squeeze().tolist() for a in x_target_list]"],"metadata":{"id":"_yEM6tn2dktZ","executionInfo":{"status":"ok","timestamp":1702063240434,"user_tz":480,"elapsed":5933,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["def accuracy(pred, target):\n","  correct = 0\n","  for i in range(len(pred)):\n","    if pred[i]==target[i]:\n","      correct+=1\n","\n","  return(correct/len(pred))"],"metadata":{"id":"BIFlYHe2TaEu","executionInfo":{"status":"ok","timestamp":1702063240435,"user_tz":480,"elapsed":5,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["conf_matrix = confusion_matrix(y_target_list, y_pred_list)\n","print(\"Confusion Matrix of the Test Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(y_pred_list, y_target_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_2SOMyQSx2H","executionInfo":{"status":"ok","timestamp":1702063240823,"user_tz":480,"elapsed":392,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"27508249-0113-4008-c060-7523ca7de169"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix of the Test Set\n","-----------------------\n","[[    0     0     0]\n"," [  199 12257 24344]\n"," [  210 12347 24243]]\n","Precision:\t0.49592391304347827\n","Recall:\t0.49592391304347827\n","F1 Score:\t0.49592391304347827\n","Accuracy:\t0.49592391304347827\n"]}]},{"cell_type":"code","source":["conf_matrix = confusion_matrix(x_target_list, x_pred_list)\n","print(\"Confusion Matrix of the Training Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(x_pred_list, x_target_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KC9NvWPU14g","executionInfo":{"status":"ok","timestamp":1702063241184,"user_tz":480,"elapsed":363,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"4418a680-4944-474e-a825-545f1e79bd9e"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix of the Training Set\n","-----------------------\n","[[    0 10125 29875]\n"," [    0  4453 12347]\n"," [    0  4421 12379]]\n","Precision:\t0.22869565217391305\n","Recall:\t0.22869565217391305\n","F1 Score:\t0.22869565217391305\n","Accuracy:\t0.22869565217391305\n"]}]},{"cell_type":"code","source":["#Accuracy per length of one barcode rather than per time point\n","import itertools\n","y_pred_list = []\n","y_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(test_data_tc):\n","    output = lstm_model(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      row_preds = []\n","      row_targets = []\n","\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        row_preds.append(np.argmax(classed))\n","        row_targets.append(np.argmax(this_target))\n","\n","        if (col+1)%92==0:\n","           row_mode_pred = max(set(row_preds), key = row_preds.count)\n","           row_mode_target = max(set(row_targets), key = row_targets.count)\n","\n","           y_pred_list.append(row_mode_pred)\n","           y_target_list.append(row_mode_target)\n","\n","           row_preds = []\n","           row_targets =[]\n","\n","y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n","y_target_list = [a.squeeze().tolist() for a in y_target_list]\n","\n","\n","#Training accuracy\n","x_pred_list = []\n","x_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(train_data_tc):\n","    output = lstm_model(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      row_preds = []\n","      row_targets = []\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        row_preds.append(np.argmax(classed))\n","        row_targets.append(np.argmax(this_target))\n","\n","        if (col+1)%92==0:\n","           row_mode_pred = max(set(row_preds), key = row_preds.count)\n","           row_mode_target = max(set(row_targets), key = row_targets.count)\n","\n","           x_pred_list.append(row_mode_pred)\n","           x_target_list.append(row_mode_target)\n","\n","           row_preds = []\n","           row_targets = []\n","\n","x_pred_list = [a.squeeze().tolist() for a in x_pred_list]\n","\n","x_target_list = [a.squeeze().tolist() for a in x_target_list]"],"metadata":{"id":"IuSbkwh8f4dG","executionInfo":{"status":"ok","timestamp":1702063251009,"user_tz":480,"elapsed":9828,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["conf_matrix = confusion_matrix(y_target_list, y_pred_list)\n","print(\"Confusion Matrix of the Test Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(y_pred_list, y_target_list)))\n","print(\"________________________\")\n","conf_matrix = confusion_matrix(x_target_list, x_pred_list)\n","print(\"Confusion Matrix of the Training Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(x_pred_list, x_target_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eAJOC7QLhhko","executionInfo":{"status":"ok","timestamp":1702063251009,"user_tz":480,"elapsed":5,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"3d0801d5-e766-4872-d235-894432f0b12b"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix of the Test Set\n","-----------------------\n","[[  0 400]\n"," [  0 400]]\n","Precision:\t0.5\n","Recall:\t0.5\n","F1 Score:\t0.5\n","Accuracy:\t0.5\n","________________________\n","Confusion Matrix of the Training Set\n","-----------------------\n","[[  0 125 275]\n"," [  0   0 200]\n"," [  0   0 200]]\n","Precision:\t0.25\n","Recall:\t0.25\n","F1 Score:\t0.25\n","Accuracy:\t0.25\n"]}]},{"cell_type":"markdown","source":["## LSTM-MLP\n"],"metadata":{"id":"41ZTbqnyV2be"}},{"cell_type":"code","source":["class LSTM_Classifier2(nn.Module):\n","  def __init__(self, input_size = 1, hidden_size = 128, hidden_size2 = 64, dropout_rate = 0.2, num_layers = 2):\n","    super(LSTM_Classifier2, self).__init__()\n","\n","    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n","\n","    self.layer1 = nn.Sequential(\n","        nn.Linear(hidden_size, hidden_size2),\n","        nn.ReLU(),\n","        nn.Dropout(dropout_rate),\n","    )\n","\n","    self.fc = nn.Linear(hidden_size2, 3)\n","    self.fc2 = nn.Linear(hidden_size, 3)\n","    self.activation = nn.Softmax(dim=2)\n","\n","  def forward(self, X):\n","    batch_size, seq_length = X.size()\n","    out = X.unsqueeze(-1).to(torch.float32)\n","    lstm_out, _ = self.lstm(out)\n","    out = lstm_out.view(batch_size, seq_length, -1)\n","\n","    out = self.layer1(out)\n","    out = self.fc(out)\n","\n","    #out = self.fc2(out)\n","    #out = self.activation(out)\n","\n","    return out.reshape([batch_size, -1, seq_length])\n","lstm_model = LSTM_Classifier2()\n","num_epochs = 250\n","learning_rate = 0.001\n","optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate)\n","\n","weights = torch.tensor([0., 1., 1.])\n","criterion = nn.CrossEntropyLoss(weight=weights)\n","\n","total_step = len(train_data_tc)\n","for epoch in range(num_epochs):\n","  for i, (X, Y) in enumerate(train_data_tc):\n","\n","    #Forward pass\n","    output = lstm_model(X)\n","    loss = criterion(output, Y.to(torch.float32))\n","    #Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  if (epoch+1) % 10==0:\n","    print(f\"Epoch: {epoch+1}/{num_epochs} - Loss: {loss.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSasWJHpV5q5","executionInfo":{"status":"ok","timestamp":1702062005751,"user_tz":480,"elapsed":2015872,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"66a6bde6-c034-4398-ea47-f389ad0153dd"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 10/250 - Loss: 4.612226963043213\n","Epoch: 20/250 - Loss: 4.54109525680542\n","Epoch: 30/250 - Loss: 4.014106750488281\n","Epoch: 40/250 - Loss: 3.912449836730957\n","Epoch: 50/250 - Loss: 3.8523998260498047\n","Epoch: 60/250 - Loss: 3.7701637744903564\n","Epoch: 70/250 - Loss: 3.4728198051452637\n","Epoch: 80/250 - Loss: 3.272183656692505\n","Epoch: 90/250 - Loss: 3.5786778926849365\n","Epoch: 100/250 - Loss: 3.314720392227173\n","Epoch: 110/250 - Loss: 3.8102211952209473\n","Epoch: 120/250 - Loss: 3.310243606567383\n","Epoch: 130/250 - Loss: 2.973111391067505\n","Epoch: 140/250 - Loss: 3.160113573074341\n","Epoch: 150/250 - Loss: 3.29512619972229\n","Epoch: 160/250 - Loss: 3.0569496154785156\n","Epoch: 170/250 - Loss: 2.7210943698883057\n","Epoch: 180/250 - Loss: 2.520073890686035\n","Epoch: 190/250 - Loss: 3.315950393676758\n","Epoch: 200/250 - Loss: 3.0765509605407715\n","Epoch: 210/250 - Loss: 2.59672212600708\n","Epoch: 220/250 - Loss: 3.4845006465911865\n","Epoch: 230/250 - Loss: 3.0638082027435303\n","Epoch: 240/250 - Loss: 2.0918092727661133\n","Epoch: 250/250 - Loss: 3.16274356842041\n"]}]},{"cell_type":"code","source":["import itertools\n","y_pred_list = []\n","y_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(test_data_tc):\n","    output = lstm_model(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        y_pred_list.append(np.argmax(classed))\n","        y_target_list.append(np.argmax(this_target))\n","\n","y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n","y_target_list = [a.squeeze().tolist() for a in y_target_list]\n","#Training accuracy\n","x_pred_list = []\n","x_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(train_data_tc):\n","    output = lstm_model(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        x_pred_list.append(np.argmax(classed))\n","        x_target_list.append(np.argmax(this_target))\n","\n","x_pred_list = [a.squeeze().tolist() for a in x_pred_list]\n","\n","x_target_list = [a.squeeze().tolist() for a in x_target_list]\n"],"metadata":{"id":"zrFtXeIbWTgI","executionInfo":{"status":"ok","timestamp":1702062019524,"user_tz":480,"elapsed":13778,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["conf_matrix = confusion_matrix(y_target_list, y_pred_list)\n","print(\"Confusion Matrix of the Test Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(y_pred_list, y_target_list)))\n","print(\"________________________\")\n","conf_matrix = confusion_matrix(x_target_list, x_pred_list)\n","print(\"Confusion Matrix of the Training Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(x_pred_list, x_target_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yw1uMLOFWW38","executionInfo":{"status":"ok","timestamp":1702062020262,"user_tz":480,"elapsed":742,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"11f6fdc8-06aa-4c6d-bfdb-408fbd12a7f4"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix of the Test Set\n","-----------------------\n","[[    0     0     0]\n"," [18124 18676     0]\n"," [19192 17608     0]]\n","Precision:\t0.25375\n","Recall:\t0.25375\n","F1 Score:\t0.25375\n","Accuracy:\t0.25375\n","________________________\n","Confusion Matrix of the Training Set\n","-----------------------\n","[[36528  1164  2308]\n"," [    0 11215  5585]\n"," [    0  6977  9823]]\n","Precision:\t0.7821467391304348\n","Recall:\t0.7821467391304348\n","F1 Score:\t0.7821467391304348\n","Accuracy:\t0.7821467391304348\n"]}]},{"cell_type":"code","source":["#Accuracy per length of one barcode rather than per time point\n","import itertools\n","y_pred_list = []\n","y_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(test_data_tc):\n","    output = lstm_model(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      row_preds = []\n","      row_targets = []\n","\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        row_preds.append(np.argmax(classed))\n","        row_targets.append(np.argmax(this_target))\n","\n","        if (col+1)%92==0:\n","           row_mode_pred = max(set(row_preds), key = row_preds.count)\n","           row_mode_target = max(set(row_targets), key = row_targets.count)\n","\n","           y_pred_list.append(row_mode_pred)\n","           y_target_list.append(row_mode_target)\n","\n","           row_preds = []\n","           row_targets =[]\n","\n","y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n","y_target_list = [a.squeeze().tolist() for a in y_target_list]\n","\n","\n","#Training accuracy\n","x_pred_list = []\n","x_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(train_data_tc):\n","    output = lstm_model(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      row_preds = []\n","      row_targets = []\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        row_preds.append(np.argmax(classed))\n","        row_targets.append(np.argmax(this_target))\n","\n","        if (col+1)%92==0:\n","           row_mode_pred = max(set(row_preds), key = row_preds.count)\n","           row_mode_target = max(set(row_targets), key = row_targets.count)\n","\n","           x_pred_list.append(row_mode_pred)\n","           x_target_list.append(row_mode_target)\n","\n","           row_preds = []\n","           row_targets = []\n","\n","x_pred_list = [a.squeeze().tolist() for a in x_pred_list]\n","\n","x_target_list = [a.squeeze().tolist() for a in x_target_list]"],"metadata":{"id":"97PRoA_fWf_N","executionInfo":{"status":"ok","timestamp":1702062034052,"user_tz":480,"elapsed":13793,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["conf_matrix = confusion_matrix(y_target_list, y_pred_list)\n","print(\"Confusion Matrix of the Test Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(y_pred_list, y_target_list)))\n","print(\"________________________\")\n","conf_matrix = confusion_matrix(x_target_list, x_pred_list)\n","print(\"Confusion Matrix of the Training Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(x_pred_list, x_target_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2JzwSsRWiFn","executionInfo":{"status":"ok","timestamp":1702062034052,"user_tz":480,"elapsed":10,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"1e26723c-25da-475a-cc73-de1217b24e44"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix of the Test Set\n","-----------------------\n","[[  0   0   0]\n"," [200 200   0]\n"," [200 200   0]]\n","Precision:\t0.25\n","Recall:\t0.25\n","F1 Score:\t0.25\n","Accuracy:\t0.25\n","________________________\n","Confusion Matrix of the Training Set\n","-----------------------\n","[[400   0   0]\n"," [  0 135  65]\n"," [  0  29 171]]\n","Precision:\t0.8825\n","Recall:\t0.8825\n","F1 Score:\t0.8825\n","Accuracy:\t0.8825\n"]}]},{"cell_type":"markdown","source":["## LSTM-MLP-0Weight"],"metadata":{"id":"saCfsDPv41C2"}},{"cell_type":"code","source":["lstm_model3 = LSTM_Classifier2()\n","num_epochs = 150\n","learning_rate = 0.001\n","optimizer = torch.optim.Adam(lstm_model3.parameters(), lr=learning_rate)\n","\n","weights = torch.tensor([0., 1., 1.])\n","criterion = nn.CrossEntropyLoss(weight=weights)\n","\n","total_step = len(train_data_tc)\n","for epoch in range(num_epochs):\n","  for i, (X, Y) in enumerate(train_data_tc):\n","\n","    #Forward pass\n","    output = lstm_model3(X)\n","    loss = criterion(output, Y.to(torch.float32))\n","    #Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  if (epoch+1) % 10==0:\n","    print(f\"Epoch: {epoch+1}/{num_epochs} - Loss: {loss.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APkQO_qL4z4C","executionInfo":{"status":"ok","timestamp":1702065428181,"user_tz":480,"elapsed":1651543,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"a5f69031-ed2e-46da-dc56-59b1c9498bd2"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 10/150 - Loss: 0.42681968212127686\n","Epoch: 20/150 - Loss: 0.3717372417449951\n","Epoch: 30/150 - Loss: 0.35812875628471375\n","Epoch: 40/150 - Loss: 0.3967970907688141\n","Epoch: 50/150 - Loss: 0.35975873470306396\n","Epoch: 60/150 - Loss: 0.3623797297477722\n","Epoch: 70/150 - Loss: 0.3503968417644501\n","Epoch: 80/150 - Loss: 0.3422216475009918\n","Epoch: 90/150 - Loss: 0.35942938923835754\n","Epoch: 100/150 - Loss: 0.35415178537368774\n","Epoch: 110/150 - Loss: 0.35468074679374695\n","Epoch: 120/150 - Loss: 0.3539099097251892\n","Epoch: 130/150 - Loss: 0.34324148297309875\n","Epoch: 140/150 - Loss: 0.34682101011276245\n","Epoch: 150/150 - Loss: 0.3435319662094116\n"]}]},{"cell_type":"code","source":["import itertools\n","y_pred_list = []\n","y_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(test_data_tc):\n","    output = lstm_model3(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        y_pred_list.append(np.argmax(classed))\n","        y_target_list.append(np.argmax(this_target))\n","\n","y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n","y_target_list = [a.squeeze().tolist() for a in y_target_list]\n","#Training accuracy\n","x_pred_list = []\n","x_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(train_data_tc):\n","    output = lstm_model3(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        x_pred_list.append(np.argmax(classed))\n","        x_target_list.append(np.argmax(this_target))\n","\n","x_pred_list = [a.squeeze().tolist() for a in x_pred_list]\n","\n","x_target_list = [a.squeeze().tolist() for a in x_target_list]\n","\n","conf_matrix = confusion_matrix(y_target_list, y_pred_list)\n","print(\"Confusion Matrix of the Test Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(y_pred_list, y_target_list)))\n","print(\"________________________\")\n","conf_matrix = confusion_matrix(x_target_list, x_pred_list)\n","print(\"Confusion Matrix of the Training Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(x_pred_list, x_target_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_GkLJJKj5FVT","executionInfo":{"status":"ok","timestamp":1702065440704,"user_tz":480,"elapsed":12529,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"c0107bae-071b-486f-8235-21956f75d398"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix of the Test Set\n","-----------------------\n","[[    0     0     0]\n"," [  998 15673 20129]\n"," [ 1015 15892 19893]]\n","Precision:\t0.4832336956521739\n","Recall:\t0.4832336956521739\n","F1 Score:\t0.4832336956521739\n","Accuracy:\t0.4832336956521739\n","________________________\n","Confusion Matrix of the Training Set\n","-----------------------\n","[[ 1135 11064 27801]\n"," [    0 11564  5236]\n"," [    0 10556  6244]]\n","Precision:\t0.25737771739130433\n","Recall:\t0.25737771739130433\n","F1 Score:\t0.25737771739130433\n","Accuracy:\t0.25737771739130433\n"]}]},{"cell_type":"code","source":["#Accuracy per length of one barcode rather than per time point\n","import itertools\n","y_pred_list = []\n","y_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(test_data_tc):\n","    output = lstm_model3(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      row_preds = []\n","      row_targets = []\n","\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        row_preds.append(np.argmax(classed))\n","        row_targets.append(np.argmax(this_target))\n","\n","        if (col+1)%92==0:\n","           row_mode_pred = max(set(row_preds), key = row_preds.count)\n","           row_mode_target = max(set(row_targets), key = row_targets.count)\n","\n","           y_pred_list.append(row_mode_pred)\n","           y_target_list.append(row_mode_target)\n","\n","           row_preds = []\n","           row_targets =[]\n","\n","y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n","y_target_list = [a.squeeze().tolist() for a in y_target_list]\n","\n","\n","#Training accuracy\n","x_pred_list = []\n","x_target_list = []\n","\n","with torch.no_grad():\n","  for i, (X,Y) in enumerate(train_data_tc):\n","    output = lstm_model3(X)\n","    output = nn.Softmax(dim=1)(output)\n","\n","    for row in range(output.shape[0]):\n","      row_preds = []\n","      row_targets = []\n","      for col in range(output.shape[2]):\n","        this_pred = output[row,:,col].detach().numpy()\n","\n","        classed = (this_pred == this_pred.max()).astype(int)\n","        this_target = Y[row,:,col].detach().numpy()\n","\n","        row_preds.append(np.argmax(classed))\n","        row_targets.append(np.argmax(this_target))\n","\n","        if (col+1)%92==0:\n","           row_mode_pred = max(set(row_preds), key = row_preds.count)\n","           row_mode_target = max(set(row_targets), key = row_targets.count)\n","\n","           x_pred_list.append(row_mode_pred)\n","           x_target_list.append(row_mode_target)\n","\n","           row_preds = []\n","           row_targets = []\n","\n","x_pred_list = [a.squeeze().tolist() for a in x_pred_list]\n","\n","x_target_list = [a.squeeze().tolist() for a in x_target_list]\n","\n","conf_matrix = confusion_matrix(y_target_list, y_pred_list)\n","print(\"Confusion Matrix of the Test Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(y_target_list, y_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(y_pred_list, y_target_list)))\n","print(\"________________________\")\n","conf_matrix = confusion_matrix(x_target_list, x_pred_list)\n","print(\"Confusion Matrix of the Training Set\")\n","print(\"-----------------------\")\n","print(conf_matrix)\n","print(\"Precision:\\t\"+str(precision_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Recall:\\t\"+str(recall_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"F1 Score:\\t\"+str(f1_score(x_target_list, x_pred_list, average=\"micro\")))\n","print(\"Accuracy:\\t\"+str(accuracy(x_pred_list, x_target_list)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vwf0wb0r5PJ5","executionInfo":{"status":"ok","timestamp":1702065451512,"user_tz":480,"elapsed":10812,"user":{"displayName":"Kai Silkwood","userId":"07019928741198237038"}},"outputId":"517ce350-563c-429d-b684-2f887f4d95b5"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix of the Test Set\n","-----------------------\n","[[ 86 314]\n"," [ 92 308]]\n","Precision:\t0.4925\n","Recall:\t0.4925\n","F1 Score:\t0.4925\n","Accuracy:\t0.4925\n","________________________\n","Confusion Matrix of the Training Set\n","-----------------------\n","[[  0 159 241]\n"," [  0 197   3]\n"," [  0 196   4]]\n","Precision:\t0.25125\n","Recall:\t0.25125\n","F1 Score:\t0.25125\n","Accuracy:\t0.25125\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"o-ABEt586CXK"},"execution_count":null,"outputs":[]}]}